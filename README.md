## Visual Question Answering in the Medical Domain

&nbsp;
  The year 2018 witnessed the inauguration of a special challenge for VQA in the medical domain under the name: the VQA-MED challenge [1], which was organized by the reputable ImageCLEF conference [2]. In 2019, the second installment of the VQA-MED challenge [3] is launched and its test dataset currently is available publicly [4].

&nbsp;

### VQA-MED-2018 Challenge:
- Overview of ImageCLEF 2018 Medical Domain Visual Question Answering Task [[Paper](http://ceur-ws.org/Vol-2125/paper_212.pdf)]
- UMass at ImageCLEF Medical Visual Question Answering (Med-VQA) 2018 Task [[Paper](http://ceur-ws.org/Vol-2125/paper_163.pdf)]
- NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain [[Paper](http://ceur-ws.org/Vol-2125/paper_212.pdf)]
- Employing Inception-Resnet-v2 and BiLSTM for Medical Domain Visual Question Answering [[Paper](http://ceur-ws.org/Vol-2125/paper_107.pdf)][[code](https://github.com/youngzhou97qz/VQA-Med/)]
- JUST at VQA-Med: A VGG-Seq2Seq Model [[Paper](http://ceur-ws.org/Vol-2125/paper_171.pdf)] [[code](https://github.com/bashartalafha/VQA-Med)]
- Deep Neural Networks and Decision Tree classifier for Visual Question Answering in the medical domain [Paper](http://ceur-ws.org/Vol-2125/paper_159.pdf)]

&nbsp;
### VQA-MED-2019 Challenge:
Will be added  when available

&nbsp;
### Reference
- [1] https://www.imageclef.org/2018/VQA-Med
- [2] https://www.imageclef.org/
- [3] https://www.imageclef.org/2019/medical/vqa
- [4] https://github.com/abachaa/VQA-Med-2019/tree/master/VQAMed2019Test
